{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='font-size:1.5em'>**üë®üèª‚Äçüè´ Week 04 lecture ‚Äì Web Scraping** </font>\n",
    "\n",
    "<font style='font-size:1.2em'>DS105W ‚Äì Data for Data Science</font>\n",
    "\n",
    "**AUTHORS:**  Dr. [Jon Cardoso-Silva](https://jonjoncardoso.github.io)\n",
    "\n",
    "**DEPARTMENT:** [LSE Data Science Institute](https://lse.ac.uk/dsi)\n",
    "\n",
    "**OBJECTIVE**: Learn how to collect data from the Web using Python packages\n",
    "\n",
    "**LAST REVISION:** 8 February 2024\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Part I: ‚öôÔ∏è The setup\n",
    "\n",
    "You will need to install the requests and Scrapy packages in order to complete this lab. I will assume you have configured the virtual environment for this course as follows. \n",
    "\n",
    "\n",
    "\n",
    "Open the terminal (directly from within VS Code will be easier) and run each of the following commands:\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install pandas requests scrapy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests               # This is how we access the web\n",
    "import pandas as pd           # This is how we work with data frames\n",
    "\n",
    "from pprint import pprint     # Print things in a pretty way\n",
    "from scrapy import Selector   # This is how we parse HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Requesting a web page\n",
    "\n",
    "\n",
    "You might have heard of [CIVICA](https://www.civica.eu/who-we-are/about-civica/) before. It is a body that unites several European universities to collaborate in the areas of social sciences, humanities, business and public policy. CIVICA hosts [Data Science Seminar series](https://socialdatascience.network/index.html#schedule) that might be of interest to you. Today we will collect information on some of the seminars. Maybe you can use it in the future! \n",
    "\n",
    "**Our main task** is to create a üêº pandas data frame that would contain:\n",
    "\n",
    "1. names of the seminars \n",
    "2. names of speakers of those seminars\n",
    "3. dates of the seminars\n",
    "4. bios of the speakers from each individual event \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Request a website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the address of the website we want to scrape\n",
    "my_url = 'https://socialdatascience.network/index.html#schedule'\n",
    "\n",
    "# We set a GET request to the website\n",
    "response = requests.get(my_url)\n",
    "\n",
    "# What is the response code?\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìú Other possible responses**\n",
    "\n",
    "The response code is standard way of communicating the status of a request. There are many other possible responses:\n",
    "\n",
    "- **200** OK\n",
    "- **204** No Content\n",
    "- **400** Bad Request\n",
    "- **401** Unauthorized\n",
    "- **402** Payment Required\n",
    "- **403** Forbidden\n",
    "- **404** Not Found\n",
    "- **500** Internal Server Error\n",
    "- **502** Bad Gateway\n",
    "\n",
    "üó£Ô∏è **CLASSROOM DISCUSSION:** Have you ever encountered any of these responses when browsing the Web on your browser? Where? What did you do about it?\n",
    "\n",
    "\n",
    "You can find a full list [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. A closer look at the response\n",
    "\n",
    "What else is stored in the `response` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vars function returns all attributes of an object, along with their values\n",
    "# You will see that it is essentially just a dictionary\n",
    "vars(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üó£Ô∏è **CLASSROOM DISCUSSION:**\n",
    "\n",
    "You have already looked at `response.status_code`. But what do you think the following attributes of the `response` object are?\n",
    "\n",
    "- `response.headers`\n",
    "- `response.cookies`\n",
    "- `response.content`\n",
    "\n",
    "Feel free to open a new chunk of code below and explore these attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But encoding is not the only **metadata** we can get from the response. Let's take a look at all the headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers are metadata about the response\n",
    "pprint(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could choose to manipulate the headers above as a `pd.Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me know you what is in the object `response` by printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code chunk above makes sense here because I want to show you how to inspect objects when in **prototype mode**. However, whenever you are writing in a Jupyter Notebook to report to someone (say, when submitting your assignment), you should remove code chunks that produce a lot of unnecessary output.\n",
    "\n",
    "\n",
    "üí° **A DETAIL THAT SEEMS INSIGNIFICANT BUT THAT IS EXTREMELY IMPORTANT**: \n",
    "- If you are on Mac or Linux, you will find that the break line character is `\\n`. \n",
    "- If you are on Windows, you will find that the break line character is `\\r\\n`. \n",
    "- Windows uses two characters to break lines, while Mac and Linux use only one. \n",
    "- This is a common source of errors when working with with text files in two different OS. (For example: you use Mac and collaborate with someone who uses Windows.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many characters are there in the `response.text`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very useful to treat is as pure string, right? We need to find a better way to parse this data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Parsing HTML\n",
    "\n",
    "The Scrapy Selector package is a Python library for extracting data from HTML and XML documents. It uses CSS or XPath selectors for data extraction making it a powerful tool for web scraping. It is often an essential part of the Scrapy framework but can also be used independently.\n",
    "\n",
    "When you feed HTML text to the Scrapy Selector, it processes the HTML and preserves it in a particular **object**. This object allows you to access parts of the HTML using Python's common dot notation in combination with the CSS syntax. If, for instance, you want to fetch the title of the page, you might use `selector.css('title')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the HTML code using Scrapy Selector\n",
    "sel = Selector(text=response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Note: I was only able to call `Selector()` directly because I had already imported it at the top of the notebook. Scroll up to see it. If I hadn't, the code above would have thrown an error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check `sel.get()` to see the full HTML document**\n",
    "\n",
    "This has the same effect as `response.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HTML documents usually have a \\<header\\> tag:**\n",
    "\n",
    "(‚ö†Ô∏è not to be confused with the HTTP header we saw with `response.headers`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css('header')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also usually a `<body>` tag, which contains the main content of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css('body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîë **Takeaway of the output above:**\n",
    "\n",
    "- The output is a list, as indicated by the square brackets. \n",
    "- HTML pages only have one `<body>` tag, so this list contains a single element, which is an object of the class Selector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to look at the content of the `<body>` tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sel.css('body').get())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are there any `<h1>` tags in this page?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css('h1').get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `<h2>` tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css('h2').getall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you care just about the **first** `<h2>` tag, you can use the `.get()` method instead of `.getall()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css(\"h2\").get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get the text from a tag:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.css(\"h2 ::text\").get()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get the text of tags returned by the `.css()` method?**\n",
    "\n",
    "You can also use `::text` on each tag element within the CSS selector returned by the `css()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Python way\n",
    "all_h2_tags = sel.css(\"h2 ::text\").getall()\n",
    "all_h2_texts = []\n",
    "\n",
    "for tag in all_h2_tags:\n",
    "    all_h2_texts.append(tag)\n",
    "\n",
    "all_h2_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider using [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp) for a cleaner code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-liner way\n",
    "all_h2_texts = [tag.get() for tag in sel.css(\"h2 ::text\")]\n",
    "all_h2_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **IMPORTANT TIPS:**\n",
    "\n",
    "- Make it a habit in the next couple of weeks to every now and then, right-click on a webpage and select \"Inspect\" (or \"Inspect Element\") to explore how the HTML is structured. This will help you understand how to use CSS selectors to extract the data you need.\n",
    "- Tag names and ` ::text` are just the tip of the iceberg. Read about other CSS selectors [here](https://www.w3schools.com/cssref/css_selectors.asp).\n",
    "- Bookmark the [Scrapy Selectors documentation page](https://docs.scrapy.org/en/latest/topics/selectors.html) and revisit it whenever you need to. Practice using different CSS selectors to extract data from the HTML."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Your turn!\n",
    "\n",
    "Let's make this a dynamic and interactive lecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **ACTION POINTS**\n",
    "\n",
    "1. Go to the [Data Science Seminar series](https://socialdatascience.network/index.html#schedule) website and inspect the page (mouse right-click + Inspect) and find the way to the name of the first event on the page. \n",
    "\n",
    "3. Write down the \"directions\" inside the HTML file to reach the event title. For example, maybe you will find that:\n",
    "\n",
    "    > _The first event title is inside a \\<html\\> ‚û°Ô∏è \\<div\\> ‚û°Ô∏è \\<div\\> ‚û°Ô∏è \\<h3\\> tag_.\n",
    "\n",
    "    Write it in the markdown cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Delete this line and write your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now, use the skill that you have just learned to scrape the names of ALL events. Save them all to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this line and replace it with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Do the same with the dates of the events and speaker names and save them to separate lists. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this line and replace it with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Combine all of these the lists into a pandas data frame and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this line and replace it with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Double-check that the CSV file was created correctly by opening it using pandas. Then convert the columns to appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this line and replace it with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Why convert the scraped data to a data frame? \n",
    "\n",
    "If time allows, we will play around with the data frame in pandas to learn a few other tricks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66a23b877595d3e158647673320c5aac91a1fe2874d6334c4fd4c069dffc5915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
